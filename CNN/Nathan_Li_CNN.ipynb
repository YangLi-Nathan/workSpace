{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "TGYtcsII67kb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sTkiNwytfRkD",
        "outputId": "cab4ccb6-de95-4fe0-e5c0-405a998bfd6a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.19.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "Xydeg_CugEBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount google drive to this notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nd1uOxCMwztv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27c4bbc-710f-45f4-8d88-d0478d46a704"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Load the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/CNN/dataset/training_set', # path to training data\n",
        "                                                           image_size=(64,64), # resize all images to 128x128\n",
        "                                                           batch_size=32)  # number of images per batch\n",
        "\n",
        "# Store class_indices before caching and prefetching\n",
        "class_names = training_set.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJQt0s_Dho9b",
        "outputId": "29178c3c-e66f-4e68-dc53-cbba310af9ec"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8060 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Load the validation set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we want to feature scaling this test\n",
        "validation_set = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/CNN/dataset/test_set', # path to training data\n",
        "                                                                    image_size=(64,64), # resize all images\n",
        "                                                                    batch_size=32)  # number of images per batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1_88wUHix9I",
        "outputId": "ef812fed-e082-46a4-82ae-986f7128061e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2120 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prefetching + caching"
      ],
      "metadata": {
        "id": "OHZiMTynl8Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "training_set = training_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_set = validation_set.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "4l4HgrhNl6-N"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "6rUDg2UCmQ83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This creates different variations of each image during training → helps the CNN generalize.\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "  tf.keras.layers.RandomZoom(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "tXs1v1HTmU09"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "E7uESOEDnEQp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.Input(shape=(64, 64, 3))) # Add Input layer\n",
        "cnn.add(data_augmentation)\n",
        "cnn.add(layers.Rescaling(1./255))"
      ],
      "metadata": {
        "id": "PwMA03d1n93E"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HSFPAAwl3TQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))"
      ],
      "metadata": {
        "id": "Mw52SGutoVhE"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.maxpool = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)"
      ],
      "metadata": {
        "id": "5KKE3C1npj_G"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "KblXlpuBpqJf"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a third convolutional layer"
      ],
      "metadata": {
        "id": "CMcgggDOp4qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "5ATIHilkp3Dh"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "_ijsG4QvqBYf"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "38iu0G1NrTgw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***add dropout to prevent overfitting"
      ],
      "metadata": {
        "id": "mZKLe25nrwbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.2))"
      ],
      "metadata": {
        "id": "OMputE-crhtw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "6vJaNQXPrzsb"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "GZe-yZazsFHW"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = validation_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQhGJ5XysKjs",
        "outputId": "c5965e58-fb68-4b43-d1ac-91e89a7270f3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 320ms/step - accuracy: 0.5034 - loss: 0.6935 - val_accuracy: 0.4717 - val_loss: 0.6937\n",
            "Epoch 2/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 252ms/step - accuracy: 0.5039 - loss: 0.6932 - val_accuracy: 0.5575 - val_loss: 0.6805\n",
            "Epoch 3/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.5475 - loss: 0.6847 - val_accuracy: 0.5882 - val_loss: 0.6689\n",
            "Epoch 4/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.5796 - loss: 0.6703 - val_accuracy: 0.6340 - val_loss: 0.6490\n",
            "Epoch 5/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.6088 - loss: 0.6598 - val_accuracy: 0.6618 - val_loss: 0.6191\n",
            "Epoch 6/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.6293 - loss: 0.6413 - val_accuracy: 0.6722 - val_loss: 0.6096\n",
            "Epoch 7/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.6311 - loss: 0.6401 - val_accuracy: 0.6778 - val_loss: 0.6002\n",
            "Epoch 8/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.6401 - loss: 0.6343 - val_accuracy: 0.6943 - val_loss: 0.5923\n",
            "Epoch 9/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 245ms/step - accuracy: 0.6625 - loss: 0.6200 - val_accuracy: 0.6896 - val_loss: 0.5918\n",
            "Epoch 10/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 253ms/step - accuracy: 0.6629 - loss: 0.6115 - val_accuracy: 0.7019 - val_loss: 0.5836\n",
            "Epoch 11/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.6742 - loss: 0.6038 - val_accuracy: 0.7005 - val_loss: 0.5769\n",
            "Epoch 12/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 245ms/step - accuracy: 0.6755 - loss: 0.6003 - val_accuracy: 0.7094 - val_loss: 0.5705\n",
            "Epoch 13/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 250ms/step - accuracy: 0.6925 - loss: 0.5819 - val_accuracy: 0.7052 - val_loss: 0.5819\n",
            "Epoch 14/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 247ms/step - accuracy: 0.6812 - loss: 0.5896 - val_accuracy: 0.7090 - val_loss: 0.5639\n",
            "Epoch 15/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.6952 - loss: 0.5822 - val_accuracy: 0.7151 - val_loss: 0.5579\n",
            "Epoch 16/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.7034 - loss: 0.5685 - val_accuracy: 0.7179 - val_loss: 0.5535\n",
            "Epoch 17/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.7041 - loss: 0.5722 - val_accuracy: 0.7071 - val_loss: 0.5587\n",
            "Epoch 18/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.7082 - loss: 0.5630 - val_accuracy: 0.7283 - val_loss: 0.5456\n",
            "Epoch 19/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 245ms/step - accuracy: 0.7173 - loss: 0.5578 - val_accuracy: 0.7250 - val_loss: 0.5357\n",
            "Epoch 20/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 245ms/step - accuracy: 0.7211 - loss: 0.5578 - val_accuracy: 0.7425 - val_loss: 0.5296\n",
            "Epoch 21/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 245ms/step - accuracy: 0.7197 - loss: 0.5531 - val_accuracy: 0.7448 - val_loss: 0.5293\n",
            "Epoch 22/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.7245 - loss: 0.5508 - val_accuracy: 0.7363 - val_loss: 0.5172\n",
            "Epoch 23/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 246ms/step - accuracy: 0.7229 - loss: 0.5368 - val_accuracy: 0.7448 - val_loss: 0.5119\n",
            "Epoch 24/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 245ms/step - accuracy: 0.7379 - loss: 0.5309 - val_accuracy: 0.7519 - val_loss: 0.5183\n",
            "Epoch 25/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 252ms/step - accuracy: 0.7343 - loss: 0.5298 - val_accuracy: 0.7505 - val_loss: 0.4989\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x792bc1f3d8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import single prediction dataset"
      ],
      "metadata": {
        "id": "FD9nar--SXxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image_A = tf.keras.utils.load_img('/content/drive/MyDrive/CNN/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image_A = tf.keras.utils.img_to_array(test_image_A)\n",
        "test_image_A = np.expand_dims(test_image_A, axis = 0)\n",
        "resultA = cnn.predict(test_image_A)\n",
        "# Use the stored class_names instead of accessing training_set.class_indices\n",
        "if resultA[0][0] > 0.5:\n",
        "  prediction_A = class_names[1] # Assuming class_names[1] is 'dog' and class_names[0] is 'cat' based on directory loading\n",
        "else:\n",
        "  prediction_A = class_names[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VZ-z_NuSWar",
        "outputId": "2e40122f-f63a-4288-f175-5e09ddbfdcf3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNCnWwFRXPP1",
        "outputId": "8601fbd5-5238-4b5c-a1c5-17b05a3019b2"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_B = tf.keras.utils.load_img('/content/drive/MyDrive/CNN/dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n",
        "test_image_B = tf.keras.utils.img_to_array(test_image_B)\n",
        "test_image_B = np.expand_dims(test_image_B, axis = 0)\n",
        "resultB = cnn.predict(test_image_B)\n",
        "# Use the stored class_names instead of accessing training_set.class_indices\n",
        "if resultB[0][0] > 0.5:\n",
        "  prediction_B = class_names[1] # Assuming class_names[1] is 'dog' and class_names[0] is 'cat' based on directory loading\n",
        "else:\n",
        "  prediction_B = class_names[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcaLFcj0XR6j",
        "outputId": "80428560-4109-42cf-d1bb-26d7159f7d3c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdkJtvD0Xody",
        "outputId": "c861b033-7669-49f3-faf5-347b73779d98"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_C = tf.keras.utils.load_img('/content/drive/MyDrive/CNN/dataset/single_prediction/cat_or_dog_3.jpg', target_size = (64, 64))\n",
        "test_image_C = tf.keras.utils.img_to_array(test_image_C)\n",
        "test_image_C = np.expand_dims(test_image_C, axis = 0)\n",
        "resultC = cnn.predict(test_image_C)\n",
        "# Use the stored class_names instead of accessing training_set.class_indices\n",
        "if resultC[0][0] > 0.5:\n",
        "  prediction_C = class_names[1] # Assuming class_names[1] is 'dog' and class_names[0] is 'cat' based on directory loading\n",
        "else:\n",
        "  prediction_C = class_names[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b4fogj_-wrF",
        "outputId": "74cfdb0c-f88d-42f6-ed3f-36a15562401e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBcriy9o_NSS",
        "outputId": "a90bd1e9-8195-4411-985c-bf30dfdc0500"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs\n"
          ]
        }
      ]
    }
  ]
}
