{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "TGYtcsII67kb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sTkiNwytfRkD",
        "outputId": "1ca459a6-23ca-437a-a903-8ac9cf00c7cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.19.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "Xydeg_CugEBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount google drive to this notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nd1uOxCMwztv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc7c091-1bf2-4d99-933e-34fc8d98e639"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Load the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Udemy/Deep Learning A-Z/Datasets/Deep Learning A-Z/Part 2 - Convolutional Neural Networks (CNN)/dataset/training_set', # path to training data\n",
        "                                                           image_size=(64,64), # resize all images to 128x128\n",
        "                                                           batch_size=32)  # number of images per batch\n",
        "\n",
        "# Store class_indices before caching and prefetching\n",
        "class_names = training_set.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJQt0s_Dho9b",
        "outputId": "8888b5d4-6a28-4e19-8f66-6211e04b0f07"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8060 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Load the validation set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we want to feature scaling this test\n",
        "validation_set = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Udemy/Deep Learning A-Z/Datasets/Deep Learning A-Z/Part 2 - Convolutional Neural Networks (CNN)/dataset/test_set', # path to training data\n",
        "                                                                    image_size=(64,64), # resize all images\n",
        "                                                                    batch_size=32)  # number of images per batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1_88wUHix9I",
        "outputId": "872879ff-a10b-43e3-dc89-e81a2af2829f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2120 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prefetching + caching"
      ],
      "metadata": {
        "id": "OHZiMTynl8Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "training_set = training_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_set = validation_set.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "4l4HgrhNl6-N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "6rUDg2UCmQ83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This creates different variations of each image during training → helps the CNN generalize.\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "  tf.keras.layers.RandomZoom(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "tXs1v1HTmU09"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "E7uESOEDnEQp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(data_augmentation)\n",
        "cnn.add(layers.Rescaling(1./255))"
      ],
      "metadata": {
        "id": "PwMA03d1n93E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw52SGutoVhE",
        "outputId": "bbc64abd-884c-42c7-cf2a-44b0570a85db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.maxpool = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)"
      ],
      "metadata": {
        "id": "5KKE3C1npj_G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "KblXlpuBpqJf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a third convolutional layer"
      ],
      "metadata": {
        "id": "CMcgggDOp4qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "5ATIHilkp3Dh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "_ijsG4QvqBYf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "38iu0G1NrTgw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***add dropout to prevent overfitting"
      ],
      "metadata": {
        "id": "mZKLe25nrwbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.2))"
      ],
      "metadata": {
        "id": "OMputE-crhtw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "6vJaNQXPrzsb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "GZe-yZazsFHW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = validation_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQhGJ5XysKjs",
        "outputId": "c36d7f9c-578e-4494-9e7b-a345165e6f0a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2127s\u001b[0m 8s/step - accuracy: 0.5452 - loss: 0.6922 - val_accuracy: 0.6509 - val_loss: 0.6283\n",
            "Epoch 2/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 213ms/step - accuracy: 0.6427 - loss: 0.6389 - val_accuracy: 0.6467 - val_loss: 0.6290\n",
            "Epoch 3/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 214ms/step - accuracy: 0.6475 - loss: 0.6302 - val_accuracy: 0.7000 - val_loss: 0.5958\n",
            "Epoch 4/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 217ms/step - accuracy: 0.6759 - loss: 0.6017 - val_accuracy: 0.6736 - val_loss: 0.5968\n",
            "Epoch 5/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.6879 - loss: 0.5870 - val_accuracy: 0.6958 - val_loss: 0.5746\n",
            "Epoch 6/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 210ms/step - accuracy: 0.7032 - loss: 0.5711 - val_accuracy: 0.6910 - val_loss: 0.5675\n",
            "Epoch 7/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 210ms/step - accuracy: 0.7123 - loss: 0.5539 - val_accuracy: 0.7193 - val_loss: 0.5486\n",
            "Epoch 8/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 215ms/step - accuracy: 0.7183 - loss: 0.5499 - val_accuracy: 0.7274 - val_loss: 0.5395\n",
            "Epoch 9/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 210ms/step - accuracy: 0.7239 - loss: 0.5424 - val_accuracy: 0.7156 - val_loss: 0.5466\n",
            "Epoch 10/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 218ms/step - accuracy: 0.7311 - loss: 0.5319 - val_accuracy: 0.7118 - val_loss: 0.5458\n",
            "Epoch 11/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 212ms/step - accuracy: 0.7344 - loss: 0.5254 - val_accuracy: 0.7561 - val_loss: 0.5208\n",
            "Epoch 12/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.7355 - loss: 0.5176 - val_accuracy: 0.7425 - val_loss: 0.5309\n",
            "Epoch 13/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 211ms/step - accuracy: 0.7335 - loss: 0.5212 - val_accuracy: 0.7528 - val_loss: 0.5133\n",
            "Epoch 14/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 211ms/step - accuracy: 0.7301 - loss: 0.5293 - val_accuracy: 0.7462 - val_loss: 0.5156\n",
            "Epoch 15/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.7495 - loss: 0.5116 - val_accuracy: 0.7458 - val_loss: 0.5070\n",
            "Epoch 16/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 215ms/step - accuracy: 0.7496 - loss: 0.5055 - val_accuracy: 0.7542 - val_loss: 0.5039\n",
            "Epoch 17/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 212ms/step - accuracy: 0.7516 - loss: 0.5005 - val_accuracy: 0.7118 - val_loss: 0.5427\n",
            "Epoch 18/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.7483 - loss: 0.5027 - val_accuracy: 0.7675 - val_loss: 0.4865\n",
            "Epoch 19/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 209ms/step - accuracy: 0.7587 - loss: 0.4893 - val_accuracy: 0.7901 - val_loss: 0.4664\n",
            "Epoch 20/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 208ms/step - accuracy: 0.7637 - loss: 0.4897 - val_accuracy: 0.7741 - val_loss: 0.4891\n",
            "Epoch 21/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 210ms/step - accuracy: 0.7627 - loss: 0.4818 - val_accuracy: 0.7943 - val_loss: 0.4640\n",
            "Epoch 22/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 212ms/step - accuracy: 0.7693 - loss: 0.4804 - val_accuracy: 0.7788 - val_loss: 0.4587\n",
            "Epoch 23/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 217ms/step - accuracy: 0.7674 - loss: 0.4737 - val_accuracy: 0.8014 - val_loss: 0.4404\n",
            "Epoch 24/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 219ms/step - accuracy: 0.7732 - loss: 0.4709 - val_accuracy: 0.7656 - val_loss: 0.4688\n",
            "Epoch 25/25\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 210ms/step - accuracy: 0.7691 - loss: 0.4682 - val_accuracy: 0.7472 - val_loss: 0.5182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x792bd02e9040>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import single prediction dataset"
      ],
      "metadata": {
        "id": "FD9nar--SXxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image_A = tf.keras.utils.load_img('/content/drive/MyDrive/Udemy/Deep Learning A-Z/Datasets/Deep Learning A-Z/Part 2 - Convolutional Neural Networks (CNN)/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image_A = tf.keras.utils.img_to_array(test_image_A)\n",
        "test_image_A = np.expand_dims(test_image_A, axis = 0)\n",
        "resultA = cnn.predict(test_image_A)\n",
        "# Use the stored class_names instead of accessing training_set.class_indices\n",
        "if resultA[0][0] == 1:\n",
        "  prediction_A = class_names[1] # Assuming class_names[1] is 'dog' and class_names[0] is 'cat' based on directory loading\n",
        "else:\n",
        "  prediction_A = class_names[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VZ-z_NuSWar",
        "outputId": "aa5c336f-cf7b-4fa7-d878-9aec9444dfe8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNCnWwFRXPP1",
        "outputId": "f5a23cff-1309-423e-8462-15f18baceac4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_B = tf.keras.utils.load_img('/content/drive/MyDrive/Udemy/Deep Learning A-Z/Datasets/Deep Learning A-Z/Part 2 - Convolutional Neural Networks (CNN)/dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n",
        "test_image_B = tf.keras.utils.img_to_array(test_image_B)\n",
        "test_image_B = np.expand_dims(test_image_B, axis = 0)\n",
        "resultB = cnn.predict(test_image_B)\n",
        "# Use the stored class_names instead of accessing training_set.class_indices\n",
        "if resultB[0][0] == 1:\n",
        "  prediction_B = class_names[1] # Assuming class_names[1] is 'dog' and class_names[0] is 'cat' based on directory loading\n",
        "else:\n",
        "  prediction_B = class_names[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcaLFcj0XR6j",
        "outputId": "d23c9112-8095-4eca-9176-6cec34e5cdfd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdkJtvD0Xody",
        "outputId": "62b80a9e-359f-4c0a-d4e0-23230119a9e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats\n"
          ]
        }
      ]
    }
  ]
}